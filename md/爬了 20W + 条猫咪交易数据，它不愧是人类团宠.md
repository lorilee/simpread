> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/sMSI0Nn4Il7LuN1gWWsOGw)

![](https://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPVhGbSxzxyMmYNIXJG7mQ49Zs7ughtKfEzCUGeqUPrdLSesIe3IyDUpFcibMcEaXxfAXzHHGNibVjEg/640?wx_fmt=png)

作者 | 叶庭云

来源 | 修炼 Python

头图 | 下载于视觉中国

![](https://mmbiz.qpic.cn/mmbiz_jpg/BnSNEaficFAYgTGBXg0ZvckYHA2iaBOsqOc2rXicCsC79VyqrfQywa6E74wdAaexVSMb4RYiacoJ9E71XJcjnkdWwA/640?wx_fmt=jpeg)

前言  

-----

看到可爱的猫咪表情包，总是会忍不住收藏，晒部分图如下：

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqXs9TQ4t07OHZS3yiae3KotU7KoUbJlQrj5bEysUmwHw4Cud5oKX3kog/640?wx_fmt=gif)

认识的一些朋友也养了猫，比如橘猫、英短、加菲猫之类的，看他们发朋友圈撸猫，老羡慕了，猫咪真的太可爱啦。发现一个专门交易猫猫的网站—猫猫交易网可以云看猫：http://www.maomijiaoyi.com/

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqaiaqglZYYpbq50rGLb8DicoWOXeE8O5SzriaObjlKHYzbQpmNicjBalPAA/640?wx_fmt=gif)

从这个网站里爬取了猫猫品种介绍的数据，以及 20W+ 条猫猫交易数据，以此来了解一下可爱的猫咪。

![](https://mmbiz.qpic.cn/mmbiz_jpg/BnSNEaficFAYgTGBXg0ZvckYHA2iaBOsqO3ToytjEfeNjJlGPcZqK98xO4MJ2zC1xj07PfS6kAic0LAlMKFBLvWPQ/640?wx_fmt=jpeg)

数据获取  

-------

打开猫猫交易网，先爬取猫咪品种数据，打开页面可以看到猫猫品种列表：

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq4hsMWLp7Oar3oG6o2qrcacE4icGqXaYQVKfjDDKAOraxbZj5BTHZqRQ/640?wx_fmt=png)

但只显示了每种猫猫的品种名，参考价格，点进详情页，可以看到更加详细的数据：品种名、参考价格、中文学名、基本信息、性格特点、生活习性、优缺点、喂养方法等。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq6OBLF1rWX79yTE295RRY6PBUQmA6p1I1vOVIoZWVG8uuHPiaw032RoQ/640?wx_fmt=png)

检查网页，可以发现网页结构简单，容易解析和提取数据。爬虫代码如下：

```
1# -*- coding: UTF-8 -*-  2"""  3@File    ：cat_kind_spider.py  4@Author  ：叶庭云  5@CSDN    ：https://yetingyun.blog.csdn.net/  6"""  7import requests  8import re  9import csv 10from lxml import etree 11from tqdm import tqdm 12from fake_useragent import UserAgent 13 14# 随机产生请求头 15ua = UserAgent(verify_ssl=False, path='fake_useragent.json') 16 17def random_ua():        # 用于随机切换请求头 18    headers = { 19        "Accept-Encoding": "gzip", 20        "Accept-Language": "zh-CN", 21        "Connection": "keep-alive", 22        "Host": "www.maomijiaoyi.com", 23        "User-Agent": ua.random 24    } 25    return headers 26 27 28def create_csv():          # 创建保存数据的csv 29    with open('./data/cat_kind.csv', 'w', newline='', encoding='utf-8') as f: 30        wr = csv.writer(f) 31        wr.writerow(['品种', '参考价格', '中文学名', '别名', '祖先', '分布区域', 32                     '原产地', '体型', '原始用途', '今日用途', '分组', '身高', 33                     '体重', '寿命', '整体', '毛发', '颜色', '头部', '眼睛', 34                     '耳朵', '鼻子', '尾巴', '胸部', '颈部', '前驱', '后驱', 35                     '基本信息', 'FCI标准', '性格特点', '生活习性', '优点/缺点', 36                     '喂养方法', '鉴别挑选']) 37 38 39def scrape_page(url1):      # 获取HTML网页源代码 返回文本 40    response = requests.get(url1, headers=random_ua()) 41    # print(response.status_code) 42    response.encoding = 'utf-8' 43    return response.text 44 45 46def get_cat_urls(html1):    # 获取每个品种猫咪详情页url 47    dom = etree.HTML(html1) 48    lis = dom.xpath('//div[@class="pinzhong_left"]/a') 49    cat_urls = [] 50    for li in lis: 51        cat_url = li.xpath('./@href')[0] 52        cat_url = 'http://www.maomijiaoyi.com' + cat_url 53        cat_urls.append(cat_url) 54    return cat_urls 55 56 57def get_info(html2):    # 爬取每个品种猫咪详情页里的有关信息 58    # 品种 59    kind = re.findall('div class="line1">.*?<div class="name">(.*?)<span>', html2, re.S)[0] 60    kind = kind.replace('\r','').replace('\n','').replace('\t','') 61    # 参考价格 62    price = re.findall('<div>参考价格：</div>.*?<div>(.*?)</div>', html2, re.S)[0] 63    price = price.replace('\r', '').replace('\n', '').replace('\t', '') 64    # 中文学名 65    chinese_name = re.findall('<div>中文学名:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 66    chinese_name = chinese_name.replace('\r', '').replace('\n', '').replace('\t', '') 67    # 别名 68    other_name = re.findall('<div>别名:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 69    other_name = other_name.replace('\r', '').replace('\n', '').replace('\t', '') 70    # 祖先 71    ancestor = re.findall('<div>祖先:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 72    ancestor = ancestor.replace('\r', '').replace('\n', '').replace('\t', '') 73    # 分布区域 74    area = re.findall('<div>分布区域:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 75    area = area.replace('\r', '').replace('\n', '').replace('\t', '') 76    # 原产地 77    source_area = re.findall('<div>原产地:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 78    source_area = source_area.replace('\r', '').replace('\n', '').replace('\t', '') 79    # 体型 80    body_size = re.findall('<div>体型:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 81    body_size = body_size.replace('\r', '').replace('\n', '').replace('\t', '').strip() 82    # 原始用途 83    source_use = re.findall('<div>原始用途:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 84    source_use = source_use.replace('\r', '').replace('\n', '').replace('\t', '') 85    # 今日用途 86    today_use = re.findall('<div>今日用途:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 87    today_use = today_use.replace('\r', '').replace('\n', '').replace('\t', '') 88    # 分组 89    group = re.findall('<div>分组:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 90    group = group.replace('\r', '').replace('\n', '').replace('\t', '') 91    # 身高 92    height = re.findall('<div>身高:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 93    height = height.replace('\r', '').replace('\n', '').replace('\t', '') 94    # 体重 95    weight = re.findall('<div>体重:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 96    weight = weight.replace('\r', '').replace('\n', '').replace('\t', '') 97    # 寿命 98    lifetime = re.findall('<div>寿命:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 99    lifetime = lifetime.replace('\r', '').replace('\n', '').replace('\t', '')100    # 整体101    entirety = re.findall('<div>整体</div>.*?<!-- 页面小折角 -->.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]102    entirety = entirety.replace('\r', '').replace('\n', '').replace('\t', '').strip()103    # 毛发104    hair = re.findall('<div>毛发</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]105    hair = hair.replace('\r', '').replace('\n', '').replace('\t', '').strip()106    # 颜色107    color = re.findall('<div>颜色</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]108    color = color.replace('\r', '').replace('\n', '').replace('\t', '').strip()109    # 头部110    head = re.findall('<div>头部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]111    head = head.replace('\r', '').replace('\n', '').replace('\t', '').strip()112    # 眼睛113    eye = re.findall('<div>眼睛</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]114    eye = eye.replace('\r', '').replace('\n', '').replace('\t', '').strip()115    # 耳朵116    ear = re.findall('<div>耳朵</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]117    ear = ear.replace('\r', '').replace('\n', '').replace('\t', '').strip()118    # 鼻子119    nose = re.findall('<div>鼻子</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]120    nose = nose.replace('\r', '').replace('\n', '').replace('\t', '').strip()121    # 尾巴122    tail = re.findall('<div>尾巴</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]123    tail = tail.replace('\r', '').replace('\n', '').replace('\t', '').strip()124    # 胸部125    chest = re.findall('<div>胸部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]126    chest = chest.replace('\r', '').replace('\n', '').replace('\t', '').strip()127    # 颈部128    neck = re.findall('<div>颈部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]129    neck = neck.replace('\r', '').replace('\n', '').replace('\t', '').strip()130    # 前驱131    font_foot = re.findall('<div>前驱</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]132    font_foot = font_foot.replace('\r', '').replace('\n', '').replace('\t', '').strip()133    # 后驱134    rear_foot = re.findall('<div>前驱</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]135    rear_foot = rear_foot.replace('\r', '').replace('\n', '').replace('\t', '').strip()136137    # 保存前面猫猫的各种有关信息138    cat = [kind, price, chinese_name, other_name, ancestor, area, source_area,139           body_size, source_use, today_use, group, height, weight, lifetime,140           entirety, hair, color, head, eye, ear, nose, tail, chest, neck, font_foot, rear_foot]141142    # 提取标签栏信息（基本信息-FCI标准-性格特点-生活习性-优缺点-喂养方法-鉴别挑选）143    html2 = etree.HTML(html2)144    labs = html2.xpath('//div[@class="property_list"]/div')145    for lab in labs:146        text1 = lab.xpath('string(.)')147        text1 = text1.replace('\n','').replace('\t','').replace('\r','').replace(' ','')148        cat.append(text1)149    return cat150151152def write_to_csv(data):     # 保存数据  追加写入153    with open('./data/cat_kind.csv', 'a+', newline='', encoding='utf-8') as fn:154        wr = csv.writer(fn)155        wr.writerow(data)156157158if __name__ == '__main__':159    # 创建保存数据的csv160    create_csv()161    # 猫咪品种页面url162    base_url = 'http://www.maomijiaoyi.com/index.php?/pinzhongdaquan_5.html'163    # 获取品种页面中的所有url164    html = scrape_page(base_url)165    urls = get_cat_urls(html)166    # 进度条可视化运行情况    就不打印东西来看了167    pbar = tqdm(urls)168    # 开始爬取169    for url in pbar:170        text = scrape_page(url)171        info = get_info(text)172        write_to_csv(info)
```

运行效果如下：

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqbxeyyo5ubtg5mFjdicviawcS00rzyiblqmS59BEHDWpjCaWqLxSBgx2ibQ/640?wx_fmt=gif)

成功爬取了猫咪品种数据保存到 csv，接下来爬取猫猫交易数据，进入到买猫卖猫页面：

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqT5OY20hGyRvqacpgzJiaXjbMKAiaHM0C2gZdnbI4XIVqPaBZWaXMmzsA/640?wx_fmt=gif)

爬取更详细的数据需要进入详情页，包含商家信息、猫咪品种、猫龄、价格、标题、在售只数、预防等信息。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqdyLpPIHbc4D3MQutKhSYxFlsLmvlsMdTz2RItaCJnrEnVVfsL7A4cA/640?wx_fmt=png)

由于数据量较大，可以分开爬取，先获取到每一页中的所有猫猫详情交易链接的 url 保存到 csv，再读取 csv 中的 url 来请求，爬取每条交易数据，爬虫思路跟前面类似，为了加快爬取效率，可以使用多线程或者异步爬虫。最终获取了 20W+ 条数据。

![](https://mmbiz.qpic.cn/mmbiz_jpg/BnSNEaficFAYgTGBXg0ZvckYHA2iaBOsqOPyiaaIVCePZnia426uNibf0PLTPfS7VRaWql6vFWCwb2Cqgjp06UvU39Q/640?wx_fmt=jpeg)

数据探索  

-------

通过词云图来直观看一下，可爱的猫咪都有那些品种。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqQmGEF2ibrXTNvf9ONOvataRAibZNmf4ItCYecgiaJHsKq3VJBpLQXCqcg/640?wx_fmt=png)

看各种猫咪的体型分布

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq7qpeeCwiaeknoHTic9evZ9slFAALYNaaibKBWpAkwsqWM1FU8oT48mRZw/640?wx_fmt=png)

所有品种的猫咪里，大型的只有一个品种，是布偶猫，其他品种都是中小型，那以后看见体型比较大的，可以先想到布偶猫。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqicLxxOibDXvTU9gJhXk0he8QvOvEcibYmpciaUGb9iaGQCicUYpOuJo2gSBA/640?wx_fmt=png)

橘猫是世界各地都有的，不愧是我大橘猫。俗话说 "十个橘猫九个胖还有一个压塌炕"。橘猫比起其他花色的猫咪更喜欢吃东西，它们的食欲很好，能更好地生存，可能这也是橘猫在世界范围都有的原因吧。可它却是小型猫，橘猫小时候颜值一般挺高，看起来小小的一只，又嫩又可爱的，但等橘猫长大以后，才真正地意识到什么是 "橘足轻重"。

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqoWUJv2vbQkoxbBNTzcsqZjZ64qmYB132OEbOy5G353PMIYvlEicichTA/640?wx_fmt=gif)

下面来看猫咪的交易数据，在交易的猫咪中，哪些品种交易数量最多呢？

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqYOEgJ8PsYGzgV09F59BwflwFKlqXyrq8N3xvXfWkLE0tv6lDC4FPxw/640?wx_fmt=png)

橘猫的交易数量最多呀，之前也提到橘猫世界各地都有，从这里也可以看到橘猫数量最多。其次是咖啡猫，布偶猫，英短蓝白猫等。

再看看卖猫商家地区分布

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqUXjw0y3yUEBnHeoibQuzPnfwicy6icqzmXicOLmzT6AiapOVc605kKdXCbQ/640?wx_fmt=png)

四川，重庆，广东是猫咪售卖商家数量最多的省份，江浙沪等地区猫咪售卖商家数量也很多，均在 10000 家以上。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqYW8lc8LNUsrkQT7dzrjCpj3uzTfWH7ojOOPGgbuYnIFjgWgkU1ibqiaw/640?wx_fmt=png)

缅因猫、布偶猫均价名列前茅啊，橘猫的均价排倒数第二，看来挺实惠。

这些售卖的猫咪猫龄一般为多大呢？

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq1saH0HxEC4NUgyjj9eo5ebOs6ejxS6p9Dd40muJx70T0lPtE9tkmuA/640?wx_fmt=png)

售卖的猫咪猫龄主要在 1-6 个月，都是刚出生还未满半岁的小猫咪呀。这时候的小猫咪应该很可爱吧，等待有缘的主人把它带回家。

最后来看一下网站里价格最贵的猫咪和浏览次数最多的猫咪

```
1# -*- coding: UTF-8 -*-  2"""  3@File    ：cat_kind_spider.py  4@Author  ：叶庭云  5@CSDN    ：https://yetingyun.blog.csdn.net/  6"""  7import requests  8import re  9import csv 10from lxml import etree 11from tqdm import tqdm 12from fake_useragent import UserAgent 13 14# 随机产生请求头 15ua = UserAgent(verify_ssl=False, path='fake_useragent.json') 16 17def random_ua():        # 用于随机切换请求头 18    headers = { 19        "Accept-Encoding": "gzip", 20        "Accept-Language": "zh-CN", 21        "Connection": "keep-alive", 22        "Host": "www.maomijiaoyi.com", 23        "User-Agent": ua.random 24    } 25    return headers 26 27 28def create_csv():          # 创建保存数据的csv 29    with open('./data/cat_kind.csv', 'w', newline='', encoding='utf-8') as f: 30        wr = csv.writer(f) 31        wr.writerow(['品种', '参考价格', '中文学名', '别名', '祖先', '分布区域', 32                     '原产地', '体型', '原始用途', '今日用途', '分组', '身高', 33                     '体重', '寿命', '整体', '毛发', '颜色', '头部', '眼睛', 34                     '耳朵', '鼻子', '尾巴', '胸部', '颈部', '前驱', '后驱', 35                     '基本信息', 'FCI标准', '性格特点', '生活习性', '优点/缺点', 36                     '喂养方法', '鉴别挑选']) 37 38 39def scrape_page(url1):      # 获取HTML网页源代码 返回文本 40    response = requests.get(url1, headers=random_ua()) 41    # print(response.status_code) 42    response.encoding = 'utf-8' 43    return response.text 44 45 46def get_cat_urls(html1):    # 获取每个品种猫咪详情页url 47    dom = etree.HTML(html1) 48    lis = dom.xpath('//div[@class="pinzhong_left"]/a') 49    cat_urls = [] 50    for li in lis: 51        cat_url = li.xpath('./@href')[0] 52        cat_url = 'http://www.maomijiaoyi.com' + cat_url 53        cat_urls.append(cat_url) 54    return cat_urls 55 56 57def get_info(html2):    # 爬取每个品种猫咪详情页里的有关信息 58    # 品种 59    kind = re.findall('div class="line1">.*?<div class="name">(.*?)<span>', html2, re.S)[0] 60    kind = kind.replace('\r','').replace('\n','').replace('\t','') 61    # 参考价格 62    price = re.findall('<div>参考价格：</div>.*?<div>(.*?)</div>', html2, re.S)[0] 63    price = price.replace('\r', '').replace('\n', '').replace('\t', '') 64    # 中文学名 65    chinese_name = re.findall('<div>中文学名:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 66    chinese_name = chinese_name.replace('\r', '').replace('\n', '').replace('\t', '') 67    # 别名 68    other_name = re.findall('<div>别名:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 69    other_name = other_name.replace('\r', '').replace('\n', '').replace('\t', '') 70    # 祖先 71    ancestor = re.findall('<div>祖先:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 72    ancestor = ancestor.replace('\r', '').replace('\n', '').replace('\t', '') 73    # 分布区域 74    area = re.findall('<div>分布区域:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 75    area = area.replace('\r', '').replace('\n', '').replace('\t', '') 76    # 原产地 77    source_area = re.findall('<div>原产地:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 78    source_area = source_area.replace('\r', '').replace('\n', '').replace('\t', '') 79    # 体型 80    body_size = re.findall('<div>体型:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 81    body_size = body_size.replace('\r', '').replace('\n', '').replace('\t', '').strip() 82    # 原始用途 83    source_use = re.findall('<div>原始用途:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 84    source_use = source_use.replace('\r', '').replace('\n', '').replace('\t', '') 85    # 今日用途 86    today_use = re.findall('<div>今日用途:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 87    today_use = today_use.replace('\r', '').replace('\n', '').replace('\t', '') 88    # 分组 89    group = re.findall('<div>分组:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 90    group = group.replace('\r', '').replace('\n', '').replace('\t', '') 91    # 身高 92    height = re.findall('<div>身高:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 93    height = height.replace('\r', '').replace('\n', '').replace('\t', '') 94    # 体重 95    weight = re.findall('<div>体重:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 96    weight = weight.replace('\r', '').replace('\n', '').replace('\t', '') 97    # 寿命 98    lifetime = re.findall('<div>寿命:</div>.*?<div>(.*?)</div>', html2, re.S)[0] 99    lifetime = lifetime.replace('\r', '').replace('\n', '').replace('\t', '')100    # 整体101    entirety = re.findall('<div>整体</div>.*?<!-- 页面小折角 -->.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]102    entirety = entirety.replace('\r', '').replace('\n', '').replace('\t', '').strip()103    # 毛发104    hair = re.findall('<div>毛发</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]105    hair = hair.replace('\r', '').replace('\n', '').replace('\t', '').strip()106    # 颜色107    color = re.findall('<div>颜色</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]108    color = color.replace('\r', '').replace('\n', '').replace('\t', '').strip()109    # 头部110    head = re.findall('<div>头部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]111    head = head.replace('\r', '').replace('\n', '').replace('\t', '').strip()112    # 眼睛113    eye = re.findall('<div>眼睛</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]114    eye = eye.replace('\r', '').replace('\n', '').replace('\t', '').strip()115    # 耳朵116    ear = re.findall('<div>耳朵</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]117    ear = ear.replace('\r', '').replace('\n', '').replace('\t', '').strip()118    # 鼻子119    nose = re.findall('<div>鼻子</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]120    nose = nose.replace('\r', '').replace('\n', '').replace('\t', '').strip()121    # 尾巴122    tail = re.findall('<div>尾巴</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]123    tail = tail.replace('\r', '').replace('\n', '').replace('\t', '').strip()124    # 胸部125    chest = re.findall('<div>胸部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]126    chest = chest.replace('\r', '').replace('\n', '').replace('\t', '').strip()127    # 颈部128    neck = re.findall('<div>颈部</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]129    neck = neck.replace('\r', '').replace('\n', '').replace('\t', '').strip()130    # 前驱131    font_foot = re.findall('<div>前驱</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]132    font_foot = font_foot.replace('\r', '').replace('\n', '').replace('\t', '').strip()133    # 后驱134    rear_foot = re.findall('<div>前驱</div>.*?<div></div>.*?<div>(.*?)</div>', html2, re.S)[0]135    rear_foot = rear_foot.replace('\r', '').replace('\n', '').replace('\t', '').strip()136137    # 保存前面猫猫的各种有关信息138    cat = [kind, price, chinese_name, other_name, ancestor, area, source_area,139           body_size, source_use, today_use, group, height, weight, lifetime,140           entirety, hair, color, head, eye, ear, nose, tail, chest, neck, font_foot, rear_foot]141142    # 提取标签栏信息（基本信息-FCI标准-性格特点-生活习性-优缺点-喂养方法-鉴别挑选）143    html2 = etree.HTML(html2)144    labs = html2.xpath('//div[@class="property_list"]/div')145    for lab in labs:146        text1 = lab.xpath('string(.)')147        text1 = text1.replace('\n','').replace('\t','').replace('\r','').replace(' ','')148        cat.append(text1)149    return cat150151152def write_to_csv(data):     # 保存数据  追加写入153    with open('./data/cat_kind.csv', 'a+', newline='', encoding='utf-8') as fn:154        wr = csv.writer(fn)155        wr.writerow(data)156157158if __name__ == '__main__':159    # 创建保存数据的csv160    create_csv()161    # 猫咪品种页面url162    base_url = 'http://www.maomijiaoyi.com/index.php?/pinzhongdaquan_5.html'163    # 获取品种页面中的所有url164    html = scrape_page(base_url)165    urls = get_cat_urls(html)166    # 进度条可视化运行情况    就不打印东西来看了167    pbar = tqdm(urls)168    # 开始爬取169    for url in pbar:170        text = scrape_page(url)171        info = get_info(text)172        write_to_csv(info)
```

```
1# -*- coding: UTF-8 -*- 2""" 3@File    ：浏览最多_价格最贵的.py 4@Author  ：叶庭云 5@CSDN    ：https://yetingyun.blog.csdn.net/ 6""" 7import pandas as pd 8 9df = pd.read_excel('处理后数据.xlsx')10print(df.info())11df1 = df.sort_values(by='浏览次数', ascending=False)12print(df1.iloc[:3, ::].values)13print('----------------------------------------------------------')14df2 = df.sort_values(by='价格', ascending=False)15print(df2.iloc[:3, ::].values)
```

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq5ibJ2uVE6CxfT20GFw4ia2r6ECzo96DVV5crze9HHCKhXVmLy1zKp9zg/640?wx_fmt=png)

浏览次数最多的是这一家卖的缅因猫，浏览次数为 16164。emmm，感觉这种猫咪看着还挺凶的，不怎么可爱。

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq3pjYTGK6FIeVQH1hjP9JxXUGK3GLC3pNSAp9YvuF08ibaR9iagqibDqVw/640?wx_fmt=png)![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq32gVMlC1xenvDWpgAJ3Wk0zaSjMdKDpvzTIiaMwsztHfFrg5vWlvM8A/640?wx_fmt=png)

反观浏览次数排第二、第三的，价格便宜不少，预防都打了 3 针疫苗，在售只数还比较充裕，还比第一可爱好多（个人感觉）。

```
1# -*- coding: UTF-8 -*- 2""" 3@File    ：浏览最多_价格最贵的.py 4@Author  ：叶庭云 5@CSDN    ：https://yetingyun.blog.csdn.net/ 6""" 7import pandas as pd 8 9df = pd.read_excel('处理后数据.xlsx')10print(df.info())11df1 = df.sort_values(by='浏览次数', ascending=False)12print(df1.iloc[:3, ::].values)13print('----------------------------------------------------------')14df2 = df.sort_values(by='价格', ascending=False)15print(df2.iloc[:3, ::].values)
```

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqNibGaOlMlYqydvPdtHVjGMarFtcOCcZLZeM56zedHIiatkqiagHiaibm9Og/640?wx_fmt=png)

![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrqtic8vs22AX13EuicGaVs3TKF0bibr3Y7s1PIFethQ6GeWqQNl1GK9iaWQQ/640?wx_fmt=png)![](https://mmbiz.qpic.cn/mmbiz_png/Nl0MnEkG9FI13m47vDn02j587viaEePrq4sr2qPaOw38fYxaasW8mhH8GlhFsFNLU20BtR7aP85d6xzfb4YJGog/640?wx_fmt=png)

价格最贵的发现均为 3000 元的布偶猫。查阅资料发现，布偶猫，大型猫咪，不仅购买的时候价格高昂，饲养成本也比较高，因为食量和运动量都比较大，而且美容等相关费用也会高一些。

![](https://mmbiz.qpic.cn/mmbiz_gif/Nl0MnEkG9FI13m47vDn02j587viaEePrqayaXpV7Gy1thBGmDicfyuP320lIZ3jEpE6yWRlW3WgBwWr61VI2iar5Q/640?wx_fmt=gif)

参考文章：

https://mp.weixin.qq.com/s/-Fh156bh1166R9fqNa6OmQ

![](https://mmbiz.qpic.cn/mmbiz_png/1hReHaqafafJYoFH7OAhmUdTjo35vvJTy1lRVjG2CzFP3arfVRDqI7a8PSS6Sx5LialaFTE1HFu2N4OIhL8jP9g/640?wx_fmt=png)